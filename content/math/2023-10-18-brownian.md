+++
title = "Brownian motion"
author = ["littlehome"]
date = 2023-10-18
lastmod = 2023-10-19T01:24:28+09:00
draft = false
+++

## Brownian motion {#brownian-motion}

<https://chat.openai.com/share/971a53a8-6c87-48d8-bed7-84d4975e2e60>

\\[
W\_{N,t} = \sum\_{i=1}^{Nt}{\frac{1}{\sqrt{N}}X\_{i}}
\\]

We are considering N events in time t.
For example, we are looking at 24 data points per day (at each hour) over multiple days.

Why are we dividing by \\( \sqrt{N} \\) but not \\( \sqrt{Nt} \\)?

In summary,


### N: {#n}

Represents the number of steps or discrete events. As \\( N \\) becomes large (approaching infinity for the continuous case), each step's contribution is scaled down by a factor of \\( \frac{1}{N} \\) so that the cumulative effect remains stationary and well-behaved. In some real-world settings like stock markets, \\( N \\) might be finite but very large, reflecting the many small price changes that occur within a given time frame.


### \\( t \\): {#t}

-   Reflects the time interval or length of observation. It's not a model parameter in the same way \\( N \\) is. Instead, it's an inherent dimension of the system being studied.
-   The variance of the process grows linearly with \\( t \\), reflecting the cumulative effects over time. As you mentioned, we do not adjust or control for \\( t \\) in the same way we do for \\( N \\); we're interested in its effects.
-   The two—\\( N \\) and \\( t \\)—indeed belong to different conceptual categories. \\( N \\) is about discretization or granularity, whereas \\( t \\) is about duration or extent.

And you're right in noting the similarity between \\( N \\) and \\( t \\) when looking at their cumulative effects: both give a linear growth in variance. But their roles and interpretations are distinct, with \\( N \\) being a model parameter (often about granularity or resolution) and \\( t \\) being an intrinsic dimension tied to the length of observation or duration.
